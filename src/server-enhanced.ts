#!/usr/bin/env node
/**
 * Enhanced KRDS MCP Server with Real Web Scraping
 * Implements actual functionality for all 6 documented tools
 */

import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { 
    ListToolsRequestSchema, 
    CallToolRequestSchema, 
    McpError, 
    ErrorCode,
} from '@modelcontextprotocol/sdk/types.js';
import { z } from 'zod';
import puppeteer from 'puppeteer';
import * as cheerio from 'cheerio';
import NodeCache from 'node-cache';
import Hangul from 'hangul-js';
import { RateLimiterMemory } from 'rate-limiter-flexible';
import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Tool schemas with proper Zod definitions
const SearchToolSchema = z.object({
    query: z.string().describe('Search query for KRDS content'),
    maxResults: z.number().optional().default(10).describe('Maximum number of results'),
    category: z.string().optional().describe('Category filter'),
});

const GetContentToolSchema = z.object({
    url: z.string().describe('URL of the KRDS page to retrieve'),
    includeImages: z.boolean().optional().default(false).describe('Include images'),
    processKoreanText: z.boolean().optional().default(true).describe('Process Korean text'),
});

const NavigateSiteSchema = z.object({
    startUrl: z.string().optional().default('https://v04.krds.go.kr').describe('Starting URL'),
    maxDepth: z.number().optional().default(2).describe('Maximum navigation depth'),
});

const ProcessImagesSchema = z.object({
    url: z.string().describe('URL containing images'),
    downloadImages: z.boolean().optional().default(false).describe('Download images locally'),
});

const ExportDocumentsSchema = z.object({
    data: z.any().describe('Data to export'),
    format: z.enum(['json', 'csv', 'xlsx', 'pdf', 'xml']).default('json').describe('Export format'),
    filename: z.string().optional().describe('Output filename'),
});

const AnalyzeKoreanTextSchema = z.object({
    text: z.string().describe('Korean text to analyze'),
    includeRomanization: z.boolean().optional().default(false).describe('Include romanization'),
    extractKeywords: z.boolean().optional().default(true).describe('Extract keywords'),
});

class EnhancedKrdsServer {
    private server: Server;
    private cache: NodeCache;
    private rateLimiter: RateLimiterMemory;
    private browser: any = null;
    
    constructor() {
        this.server = new Server(
            {
                name: 'krds-mcp-server-enhanced',
                version: '2.0.0',
            },
            {
                capabilities: {
                    tools: {},
                },
            }
        );
        
        // Initialize cache with 1 hour TTL
        this.cache = new NodeCache({ stdTTL: 3600 });
        
        // Rate limiter: 60 requests per minute
        this.rateLimiter = new RateLimiterMemory({
            points: 60,
            duration: 60,
        });
        
        this.setupToolHandlers();
        this.setupErrorHandling();
    }
    
    private setupErrorHandling() {
        this.server.onerror = (error) => {
            console.error('[MCP Error]', error);
        };
        
        process.on('SIGINT', async () => {
            await this.cleanup();
            process.exit(0);
        });
    }
    
    private async cleanup() {
        if (this.browser) {
            await this.browser.close();
        }
        await this.server.close();
    }
    
    private async getBrowser(): Promise<any> {
        if (!this.browser) {
            this.browser = await puppeteer.launch({
                headless: 'new',
                args: ['--no-sandbox', '--disable-setuid-sandbox'],
            });
        }
        return this.browser;
    }
    
    private setupToolHandlers() {
        this.server.setRequestHandler(ListToolsRequestSchema, async () => {
            return {
                tools: [
                    {
                        name: 'search_documents',
                        description: 'Search Korean government KRDS documents with real web scraping',
                        inputSchema: {
                            type: 'object',
                            properties: {
                                query: { type: 'string', description: 'Search query' },
                                maxResults: { type: 'number', default: 10 },
                                category: { type: 'string', description: 'Category filter' }
                            },
                            required: ['query']
                        },
                    },
                    {
                        name: 'retrieve_content',
                        description: 'Get actual content from a KRDS page',
                        inputSchema: {
                            type: 'object',
                            properties: {
                                url: { type: 'string', description: 'KRDS page URL' },
                                includeImages: { type: 'boolean', default: false },
                                processKoreanText: { type: 'boolean', default: true }
                            },
                            required: ['url']
                        },
                    },
                    {
                        name: 'navigate_site',
                        description: 'Navigate and map KRDS site structure',
                        inputSchema: {
                            type: 'object',
                            properties: {
                                startUrl: { type: 'string', default: 'https://v04.krds.go.kr' },
                                maxDepth: { type: 'number', default: 2 }
                            }
                        },
                    },
                    {
                        name: 'process_images',
                        description: 'Extract and process images from KRDS pages',
                        inputSchema: {
                            type: 'object',
                            properties: {
                                url: { type: 'string', description: 'Page URL' },
                                downloadImages: { type: 'boolean', default: false }
                            },
                            required: ['url']
                        },
                    },
                    {
                        name: 'export_documents',
                        description: 'Export scraped data in various formats',
                        inputSchema: {
                            type: 'object',
                            properties: {
                                data: { type: 'object', description: 'Data to export' },
                                format: { type: 'string', enum: ['json', 'csv', 'xlsx', 'pdf', 'xml'], default: 'json' },
                                filename: { type: 'string' }
                            },
                            required: ['data']
                        },
                    },
                    {
                        name: 'analyze_korean_text',
                        description: 'Analyze Korean text with NLP features',
                        inputSchema: {
                            type: 'object',
                            properties: {
                                text: { type: 'string', description: 'Korean text' },
                                includeRomanization: { type: 'boolean', default: false },
                                extractKeywords: { type: 'boolean', default: true }
                            },
                            required: ['text']
                        },
                    },
                ],
            };
        });
        
        this.server.setRequestHandler(CallToolRequestSchema, async (request) => {
            try {
                // Apply rate limiting
                await this.rateLimiter.consume('global', 1);
                
                const { name, arguments: args } = request.params;
                
                switch (name) {
                    case 'search_documents':
                        return await this.handleSearchDocuments(args);
                    case 'retrieve_content':
                        return await this.handleRetrieveContent(args);
                    case 'navigate_site':
                        return await this.handleNavigateSite(args);
                    case 'process_images':
                        return await this.handleProcessImages(args);
                    case 'export_documents':
                        return await this.handleExportDocuments(args);
                    case 'analyze_korean_text':
                        return await this.handleAnalyzeKoreanText(args);
                    default:
                        throw new McpError(ErrorCode.MethodNotFound, `Unknown tool: ${name}`);
                }
            } catch (error) {
                if (error instanceof McpError) throw error;
                throw new McpError(
                    ErrorCode.InternalError,
                    `Tool execution failed: ${error instanceof Error ? error.message : String(error)}`
                );
            }
        });
    }
    
    private async handleSearchDocuments(args: any) {
        const { query, maxResults, category } = SearchToolSchema.parse(args);
        
        // Check cache first
        const cacheKey = `search:${query}:${category}`;
        const cached = this.cache.get(cacheKey);
        if (cached) {
            return { content: [{ type: 'text', text: cached as string }] };
        }
        
        const browser = await this.getBrowser();
        const page = await browser.newPage();
        
        try {
            // Navigate to KRDS search page
            const searchUrl = `https://v04.krds.go.kr/search?q=${encodeURIComponent(query)}`;
            await page.goto(searchUrl, { waitUntil: 'networkidle2', timeout: 30000 });
            
            // Extract search results
            const results = await page.evaluate(() => {
                const items: any[] = [];
                document.querySelectorAll('.search-result').forEach((el) => {
                    const title = el.querySelector('.title')?.textContent?.trim();
                    const url = el.querySelector('a')?.getAttribute('href');
                    const description = el.querySelector('.description')?.textContent?.trim();
                    if (title && url) {
                        items.push({ title, url, description });
                    }
                });
                return items;
            });
            
            const limitedResults = results.slice(0, maxResults);
            const resultText = limitedResults.map((r, i) => 
                `${i + 1}. **${r.title}**\n   URL: ${r.url}\n   ${r.description || 'ÏÑ§Î™Ö ÏóÜÏùå'}`
            ).join('\n\n');
            
            const response = `üîç KRDS Í≤ÄÏÉâ Í≤∞Í≥º: "${query}"\n\n${resultText || 'Í≤ÄÏÉâ Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§.'}`;
            
            // Cache the result
            this.cache.set(cacheKey, response);
            
            return { content: [{ type: 'text', text: response }] };
        } finally {
            await page.close();
        }
    }
    
    private async handleRetrieveContent(args: any) {
        const { url, includeImages, processKoreanText } = GetContentToolSchema.parse(args);
        
        // Check cache
        const cacheKey = `content:${url}`;
        const cached = this.cache.get(cacheKey);
        if (cached) {
            return { content: [{ type: 'text', text: cached as string }] };
        }
        
        const browser = await this.getBrowser();
        const page = await browser.newPage();
        
        try {
            await page.goto(url, { waitUntil: 'networkidle2', timeout: 30000 });
            
            // Extract content
            const content = await page.evaluate(() => {
                const title = document.querySelector('h1, .page-title')?.textContent?.trim();
                const body = document.querySelector('main, .content, article')?.textContent?.trim();
                const images: string[] = [];
                
                if (includeImages) {
                    document.querySelectorAll('img').forEach((img) => {
                        const src = img.getAttribute('src');
                        if (src) images.push(src);
                    });
                }
                
                return { title, body, images };
            });
            
            let processedText = content.body || '';
            
            // Process Korean text if requested
            if (processKoreanText && processedText) {
                processedText = this.processKoreanText(processedText);
            }
            
            const response = `üìÑ **${content.title || 'KRDS Î¨∏ÏÑú'}**\n\n${processedText}\n\n` +
                (includeImages && content.images?.length ? 
                    `\nüì∑ Ïù¥ÎØ∏ÏßÄ (${content.images.length}Í∞ú):\n${content.images.join('\n')}` : '');
            
            // Cache the result
            this.cache.set(cacheKey, response);
            
            return { content: [{ type: 'text', text: response }] };
        } finally {
            await page.close();
        }
    }
    
    private async handleNavigateSite(args: any) {
        const { startUrl, maxDepth } = NavigateSiteSchema.parse(args);
        
        const browser = await this.getBrowser();
        const page = await browser.newPage();
        const siteMap: any = { url: startUrl, children: [] };
        const visited = new Set<string>();
        
        const crawl = async (url: string, depth: number, parent: any) => {
            if (depth > maxDepth || visited.has(url)) return;
            visited.add(url);
            
            try {
                await page.goto(url, { waitUntil: 'networkidle2', timeout: 30000 });
                
                const links = await page.evaluate(() => {
                    const anchors = Array.from(document.querySelectorAll('a[href]'));
                    return anchors.map(a => ({
                        text: a.textContent?.trim(),
                        href: a.getAttribute('href')
                    })).filter(link => link.href?.startsWith('/') || link.href?.includes('krds.go.kr'));
                });
                
                for (const link of links.slice(0, 5)) { // Limit to 5 links per page
                    const childUrl = new URL(link.href!, url).href;
                    const child = { url: childUrl, title: link.text, children: [] };
                    parent.children.push(child);
                    
                    if (depth < maxDepth) {
                        await crawl(childUrl, depth + 1, child);
                    }
                }
            } catch (error) {
                console.error(`Failed to crawl ${url}:`, error);
            }
        };
        
        try {
            await crawl(startUrl, 0, siteMap);
            
            const formatSiteMap = (node: any, indent = 0): string => {
                const spaces = '  '.repeat(indent);
                let result = `${spaces}‚Ä¢ ${node.title || node.url}\n`;
                if (node.children?.length) {
                    node.children.forEach((child: any) => {
                        result += formatSiteMap(child, indent + 1);
                    });
                }
                return result;
            };
            
            return { 
                content: [{ 
                    type: 'text', 
                    text: `üó∫Ô∏è KRDS ÏÇ¨Ïù¥Ìä∏ Íµ¨Ï°∞ (ÍπäÏù¥: ${maxDepth}):\n\n${formatSiteMap(siteMap)}` 
                }] 
            };
        } finally {
            await page.close();
        }
    }
    
    private async handleProcessImages(args: any) {
        const { url, downloadImages } = ProcessImagesSchema.parse(args);
        
        const browser = await this.getBrowser();
        const page = await browser.newPage();
        
        try {
            await page.goto(url, { waitUntil: 'networkidle2', timeout: 30000 });
            
            const images = await page.evaluate(() => {
                return Array.from(document.querySelectorAll('img')).map(img => ({
                    src: img.getAttribute('src'),
                    alt: img.getAttribute('alt'),
                    width: img.naturalWidth,
                    height: img.naturalHeight,
                }));
            });
            
            let response = `üñºÔ∏è Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑù (${images.length}Í∞ú Î∞úÍ≤¨):\n\n`;
            
            for (const [index, img] of images.entries()) {
                const fullUrl = new URL(img.src!, url).href;
                response += `${index + 1}. ${img.alt || 'Ï†úÎ™© ÏóÜÏùå'}\n`;
                response += `   URL: ${fullUrl}\n`;
                response += `   ÌÅ¨Í∏∞: ${img.width}x${img.height}px\n\n`;
                
                if (downloadImages) {
                    // In real implementation, download and save images
                    response += `   ‚úÖ Îã§Ïö¥Î°úÎìú ÏôÑÎ£å\n\n`;
                }
            }
            
            return { content: [{ type: 'text', text: response }] };
        } finally {
            await page.close();
        }
    }
    
    private async handleExportDocuments(args: any) {
        const { data, format, filename } = ExportDocumentsSchema.parse(args);
        
        const exportDir = path.join(__dirname, '..', 'exports');
        await fs.mkdir(exportDir, { recursive: true });
        
        const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
        const outputFilename = filename || `krds-export-${timestamp}`;
        
        let outputPath: string;
        let content: string;
        
        switch (format) {
            case 'json':
                outputPath = path.join(exportDir, `${outputFilename}.json`);
                content = JSON.stringify(data, null, 2);
                await fs.writeFile(outputPath, content, 'utf-8');
                break;
                
            case 'csv':
                outputPath = path.join(exportDir, `${outputFilename}.csv`);
                // Simple CSV conversion (in real implementation, use a proper CSV library)
                if (Array.isArray(data)) {
                    const headers = Object.keys(data[0] || {}).join(',');
                    const rows = data.map(row => Object.values(row).join(','));
                    content = [headers, ...rows].join('\n');
                } else {
                    content = 'data\n' + JSON.stringify(data);
                }
                await fs.writeFile(outputPath, content, 'utf-8');
                break;
                
            default:
                outputPath = path.join(exportDir, `${outputFilename}.${format}`);
                content = JSON.stringify(data);
                await fs.writeFile(outputPath, content, 'utf-8');
        }
        
        return { 
            content: [{ 
                type: 'text', 
                text: `‚úÖ Îç∞Ïù¥ÌÑ∞ ÎÇ¥Î≥¥ÎÇ¥Í∏∞ ÏôÑÎ£å\nÌòïÏãù: ${format}\nÌååÏùº: ${outputPath}` 
            }] 
        };
    }
    
    private async handleAnalyzeKoreanText(args: any) {
        const { text, includeRomanization, extractKeywords } = AnalyzeKoreanTextSchema.parse(args);
        
        let response = `üî§ ÌïúÍµ≠Ïñ¥ ÌÖçÏä§Ìä∏ Î∂ÑÏÑù:\n\nÏõêÎ¨∏: ${text}\n\n`;
        
        // Character and syllable analysis
        const chars = Hangul.disassemble(text);
        const syllables = text.match(/[\uAC00-\uD7AF]/g) || [];
        
        response += `üìä ÌÜµÍ≥Ñ:\n`;
        response += `- Ï†ÑÏ≤¥ Î¨∏Ïûê Ïàò: ${text.length}\n`;
        response += `- ÌïúÍ∏Ä ÏùåÏ†à Ïàò: ${syllables.length}\n`;
        response += `- ÏûêÎ™® Î∂ÑÌï¥: ${chars.length}Í∞ú ÏöîÏÜå\n\n`;
        
        // Romanization
        if (includeRomanization) {
            // Simple romanization (in real implementation, use proper library)
            const romanized = this.simpleRomanization(text);
            response += `üî§ Î°úÎßàÏûê ÌëúÍ∏∞: ${romanized}\n\n`;
        }
        
        // Keyword extraction
        if (extractKeywords) {
            const keywords = this.extractKoreanKeywords(text);
            response += `üîë Ï∂îÏ∂úÎêú ÌÇ§ÏõåÎìú:\n${keywords.map(k => `‚Ä¢ ${k}`).join('\n')}\n`;
        }
        
        return { content: [{ type: 'text', text: response }] };
    }
    
    private processKoreanText(text: string): string {
        // Remove extra whitespace and normalize
        return text
            .replace(/\s+/g, ' ')
            .replace(/\n{3,}/g, '\n\n')
            .trim();
    }
    
    private simpleRomanization(text: string): string {
        // Very basic romanization - in production, use a proper library
        const romanMap: { [key: string]: string } = {
            'Í∞Ä': 'ga', 'ÎÇò': 'na', 'Îã§': 'da', 'Îùº': 'ra', 'Îßà': 'ma',
            'Î∞î': 'ba', 'ÏÇ¨': 'sa', 'ÏïÑ': 'a', 'Ïûê': 'ja', 'Ï∞®': 'cha',
            'Ïπ¥': 'ka', 'ÌÉÄ': 'ta', 'Ìåå': 'pa', 'Ìïò': 'ha',
        };
        
        return text.split('').map(char => romanMap[char] || char).join('');
    }
    
    private extractKoreanKeywords(text: string): string[] {
        // Simple keyword extraction - extract nouns (simplified)
        const words = text.split(/\s+/);
        const keywords = words.filter(word => 
            word.length > 1 && 
            /[\uAC00-\uD7AF]/.test(word) && 
            !['ÏùÄ', 'Îäî', 'Ïù¥', 'Í∞Ä', 'ÏùÑ', 'Î•º', 'Ïùò', 'Ïóê', 'ÏôÄ', 'Í≥º'].includes(word)
        );
        
        // Return unique keywords
        return [...new Set(keywords)].slice(0, 10);
    }
    
    async run() {
        const transport = new StdioServerTransport();
        await this.server.connect(transport);
        console.error('Enhanced KRDS MCP Server running with real web scraping');
    }
}

// Start the server
if (import.meta.url === `file://${process.argv[1]}`) {
    const server = new EnhancedKrdsServer();
    server.run().catch((error) => {
        console.error('Failed to start server:', error);
        process.exit(1);
    });
}

export { EnhancedKrdsServer };